# Database
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/cv_reformatter?schema=public"

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# Compatible avec tous les LLM utilisant le format OpenAI Chat Completions.
# Décommente et configure UN SEUL provider ci-dessous.
# =============================================================================

# -----------------------------------------------------------------------------
# OPENAI
# -----------------------------------------------------------------------------
# LLM_API_KEY="sk-proj-..."
# LLM_ENDPOINT="https://api.openai.com/v1/chat/completions"
# LLM_MODEL="gpt-4o"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# MISTRAL
# -----------------------------------------------------------------------------
# LLM_API_KEY="..."
# LLM_ENDPOINT="https://api.mistral.ai/v1/chat/completions"
# LLM_MODEL="mistral-large-latest"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# GROQ (Llama, Mixtral, Gemma)
# -----------------------------------------------------------------------------
# LLM_API_KEY="gsk_..."
# LLM_ENDPOINT="https://api.groq.com/openai/v1/chat/completions"
# LLM_MODEL="llama-3.3-70b-versatile"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# TOGETHER AI (Llama, Mixtral, Qwen, etc.)
# -----------------------------------------------------------------------------
# LLM_API_KEY="..."
# LLM_ENDPOINT="https://api.together.xyz/v1/chat/completions"
# LLM_MODEL="meta-llama/Llama-3.3-70B-Instruct-Turbo"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# DEEPSEEK
# -----------------------------------------------------------------------------
# LLM_API_KEY="sk-..."
# LLM_ENDPOINT="https://api.deepseek.com/chat/completions"
# LLM_MODEL="deepseek-chat"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# GEMINI (Google)
# -----------------------------------------------------------------------------
# LLM_API_KEY="..."
# LLM_ENDPOINT="https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
# LLM_MODEL="gemini-2.0-flash"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# OPENROUTER (Accès à tous les modèles via une seule API)
# -----------------------------------------------------------------------------
# LLM_API_KEY="sk-or-..."
# LLM_ENDPOINT="https://openrouter.ai/api/v1/chat/completions"
# LLM_MODEL="anthropic/claude-3.5-sonnet"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# FIREWORKS AI
# -----------------------------------------------------------------------------
# LLM_API_KEY="fw_..."
# LLM_ENDPOINT="https://api.fireworks.ai/inference/v1/chat/completions"
# LLM_MODEL="accounts/fireworks/models/llama-v3p3-70b-instruct"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# PERPLEXITY
# -----------------------------------------------------------------------------
# LLM_API_KEY="pplx-..."
# LLM_ENDPOINT="https://api.perplexity.ai/chat/completions"
# LLM_MODEL="llama-3.1-sonar-large-128k-online"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# OLLAMA (Local)
# -----------------------------------------------------------------------------
# LLM_API_KEY="ollama"
# LLM_ENDPOINT="http://localhost:11434/v1/chat/completions"
# LLM_MODEL="llama3.2"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# LM STUDIO (Local)
# -----------------------------------------------------------------------------
# LLM_API_KEY="lm-studio"
# LLM_ENDPOINT="http://localhost:1234/v1/chat/completions"
# LLM_MODEL="local-model"
# LLM_MAX_TOKENS="8192"

# -----------------------------------------------------------------------------
# AZURE OPENAI
# -----------------------------------------------------------------------------
# LLM_API_KEY="..."
# LLM_ENDPOINT="https://{resource-name}.openai.azure.com/openai/deployments/{deployment-name}/chat/completions?api-version=2024-02-15-preview"
# LLM_MODEL="gpt-4o"
# LLM_MAX_TOKENS="8192"

# =============================================================================
# CONFIGURATION PAR DEFAUT (à modifier)
# =============================================================================
LLM_API_KEY=""
LLM_ENDPOINT="https://api.openai.com/v1/chat/completions"
LLM_MODEL="gpt-4o"
LLM_MAX_TOKENS="8192"

# =============================================================================
# BACKBLAZE B2 (S3-compatible)
# =============================================================================
B2_ENDPOINT="https://s3.us-west-004.backblazeb2.com"
B2_REGION="us-west-004"
B2_ACCESS_KEY_ID=""
B2_SECRET_ACCESS_KEY=""
B2_BUCKET_NAME="cv-uploads"
B2_BUCKET_CV_RAW="cv-raw"
B2_BUCKET_CV_FINAL="cv-final"

# =============================================================================
# APP
# =============================================================================
NEXT_PUBLIC_APP_URL="http://localhost:3000"

# =============================================================================
# REDIS (pour BullMQ)
# =============================================================================
REDIS_HOST="localhost"
REDIS_PORT="6379"
REDIS_PASSWORD=""

# =============================================================================
# WORKER
# =============================================================================
WORKER_CONCURRENCY="5"
